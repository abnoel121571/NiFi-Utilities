<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<template encoding-version="1.4">
    <description>Optimized Oracle to Azure Data Lake flow template with performance tuning parameters</description>
    <name>Oracle-to-AzureDataLake-Optimized</name>
    <groupId>oracle-azure-migration</groupId>
    <version>1.0</version>
    
    <!-- Process Group: Oracle Data Extraction -->
    <snippet>
        <processGroups>
            <id>oracle-extraction-pg</id>
            <name>Oracle Data Extraction</name>
            <position x="100" y="100"/>
            
            <!-- Controller Services -->
            <controllerServices>
                <!-- Optimized Oracle DBCP Connection Pool -->
                <controllerService>
                    <id>oracle-dbcp-service</id>
                    <name>Oracle-DBCP-ConnectionPool-Optimized</name>
                    <type>org.apache.nifi.dbcp.DBCPConnectionPool</type>
                    <properties>
                        <!-- Database Connection Settings -->
                        <property name="Database Connection URL">jdbc:oracle:thin:@//your-oracle-host:1521/your-service-name</property>
                        <property name="Database Driver Class Name">oracle.jdbc.driver.OracleDriver</property>
                        <property name="Database User">your_username</property>
                        <property name="Password">your_password</property>
                        
                        <!-- Performance Optimization Settings -->
                        <property name="Max Wait Time">30 seconds</property>
                        <property name="Max Total Connections">25</property>
                        <property name="Max Idle Connections">15</property>
                        <property name="Min Idle Connections">5</property>
                        <property name="Initial Size">5</property>
                        
                        <!-- Connection Validation -->
                        <property name="Validation Query">SELECT 1 FROM DUAL</property>
                        <property name="Test On Borrow">true</property>
                        <property name="Test While Idle">true</property>
                        <property name="Time Between Eviction Runs">60 seconds</property>
                        <property name="Min Evictable Idle Time">30 minutes</property>
                        
                        <!-- Oracle Specific Optimizations -->
                        <property name="Additional Properties">
                            oracle.net.CONNECT_TIMEOUT=10000;
                            oracle.net.READ_TIMEOUT=30000;
                            oracle.jdbc.defaultRowPrefetch=50000;
                            oracle.jdbc.ReadTimeout=60000;
                            defaultBatchValue=1000;
                            oracle.jdbc.implicitStatementCacheSize=25;
                            oracle.jdbc.explicitStatementCacheSize=25
                        </property>
                    </properties>
                </controllerService>
                
                <!-- Azure Data Lake Storage Service -->
                <controllerService>
                    <id>azure-storage-service</id>
                    <name>Azure-DataLake-Storage-Service</name>
                    <type>org.apache.nifi.processors.azure.storage.AzureStorageCredentialsService</type>
                    <properties>
                        <property name="Storage Account Name">yourstorageaccount</property>
                        <property name="Storage Account Key">your-storage-account-key</property>
                        <!-- Use Managed Identity for production -->
                        <property name="Use Managed Identity">false</property>
                    </properties>
                </controllerService>
            </controllerServices>
            
            <!-- Processors -->
            <processors>
                <!-- 1. Query Oracle Database -->
                <processor>
                    <id>query-oracle-processor</id>
                    <name>Query-Oracle-Data</name>
                    <type>org.apache.nifi.processors.standard.ExecuteSQL</type>
                    <position x="200" y="200"/>
                    
                    <properties>
                        <!-- Database Connection -->
                        <property name="Database Connection Pooling Service">oracle-dbcp-service</property>
                        
                        <!-- Performance Tuning -->
                        <property name="SQL select query">
                            SELECT /*+ FIRST_ROWS(50000) PARALLEL(4) */ 
                            * FROM your_table 
                            WHERE modified_date >= ? 
                            AND modified_date < ?
                            ORDER BY id
                        </property>
                        
                        <!-- Fetch Size Optimization -->
                        <property name="Fetch Size">50000</property>
                        <property name="Max Rows Per Flow File">50000</property>
                        
                        <!-- Query Parameters for Incremental Loading -->
                        <property name="SQL select query">
                            ${sql.args.1:SET}${sql.args.2:SET}
                        </property>
                        
                        <!-- Normalize Table/Column Names -->
                        <property name="Normalize Table/Column Names">true</property>
                        <property name="Use Avro Logical Types">true</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>TIMER_DRIVEN</schedulingStrategy>
                    <schedulingPeriod>300 sec</schedulingPeriod>
                    <maxConcurrentTasks>2</maxConcurrentTasks>
                    
                    <!-- Run Schedule -->
                    <runDurationMillis>0</runDurationMillis>
                    <yieldDurationMillis>10000</yieldDurationMillis>
                </processor>
                
                <!-- 2. Split Large Results -->
                <processor>
                    <id>split-avro-processor</id>
                    <name>Split-Large-Results</name>
                    <type>org.apache.nifi.processors.avro.SplitAvro</type>
                    <position x="400" y="200"/>
                    
                    <properties>
                        <!-- Split Configuration -->
                        <property name="Output Size">10000</property>
                        <property name="Transfer Metadata">true</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>4</maxConcurrentTasks>
                    <yieldDurationMillis>1000</yieldDurationMillis>
                </processor>
                
                <!-- 3. Compress Data for Network Transfer -->
                <processor>
                    <id>compress-processor</id>
                    <name>Compress-for-Transfer</name>
                    <type>org.apache.nifi.processors.standard.CompressContent</type>
                    <position x="600" y="200"/>
                    
                    <properties>
                        <property name="Mode">compress</property>
                        <property name="Compression Format">gzip</property>
                        <property name="Compression Level">6</property>
                        <property name="Update Filename">true</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>8</maxConcurrentTasks>
                </processor>
                
                <!-- 4. Route Based on File Size -->
                <processor>
                    <id>route-filesize-processor</id>
                    <name>Route-by-FileSize</name>
                    <type>org.apache.nifi.processors.standard.RouteOnAttribute</type>
                    <position x="800" y="200"/>
                    
                    <properties>
                        <property name="Routing Strategy">Route to Property name</property>
                        <!-- Small files: < 10MB -->
                        <property name="small_file">${fileSize:lt(10485760)}</property>
                        <!-- Medium files: 10MB - 100MB -->
                        <property name="medium_file">${fileSize:ge(10485760):and(${fileSize:lt(104857600)})}</property>
                        <!-- Large files: >= 100MB -->
                        <property name="large_file">${fileSize:ge(104857600)}</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>4</maxConcurrentTasks>
                </processor>
                
                <!-- 5a. Azure Data Lake Writer - Small Files -->
                <processor>
                    <id>azure-writer-small</id>
                    <name>Azure-Writer-Small-Files</name>
                    <type>org.apache.nifi.processors.azure.storage.PutAzureDataLakeStorage</type>
                    <position x="1000" y="100"/>
                    
                    <properties>
                        <!-- Azure Configuration -->
                        <property name="Azure Storage Credentials Service">azure-storage-service</property>
                        <property name="Filesystem Name">nifi-data</property>
                        <property name="Directory Name">oracle-data/small/${now():format('yyyy/MM/dd')}</property>
                        <property name="File Name">${filename}</property>
                        
                        <!-- Performance Settings for Small Files -->
                        <property name="Block Size">4 MB</property>
                        <property name="Buffer Size">1 MB</property>
                        <property name="Number of Retries">5</property>
                        <property name="Create Directory">true</property>
                        
                        <!-- Conflict Resolution -->
                        <property name="Conflict Resolution Strategy">replace</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>8</maxConcurrentTasks>
                    <yieldDurationMillis>5000</yieldDurationMillis>
                </processor>
                
                <!-- 5b. Azure Data Lake Writer - Medium Files -->
                <processor>
                    <id>azure-writer-medium</id>
                    <name>Azure-Writer-Medium-Files</name>
                    <type>org.apache.nifi.processors.azure.storage.PutAzureDataLakeStorage</type>
                    <position x="1000" y="200"/>
                    
                    <properties>
                        <!-- Azure Configuration -->
                        <property name="Azure Storage Credentials Service">azure-storage-service</property>
                        <property name="Filesystem Name">nifi-data</property>
                        <property name="Directory Name">oracle-data/medium/${now():format('yyyy/MM/dd')}</property>
                        <property name="File Name">${filename}</property>
                        
                        <!-- Performance Settings for Medium Files -->
                        <property name="Block Size">16 MB</property>
                        <property name="Buffer Size">4 MB</property>
                        <property name="Number of Retries">5</property>
                        <property name="Create Directory">true</property>
                        
                        <!-- Conflict Resolution -->
                        <property name="Conflict Resolution Strategy">replace</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>4</maxConcurrentTasks>
                    <yieldDurationMillis>5000</yieldDurationMillis>
                </processor>
                
                <!-- 5c. Azure Data Lake Writer - Large Files -->
                <processor>
                    <id>azure-writer-large</id>
                    <name>Azure-Writer-Large-Files</name>
                    <type>org.apache.nifi.processors.azure.storage.PutAzureDataLakeStorage</type>
                    <position x="1000" y="300"/>
                    
                    <properties>
                        <!-- Azure Configuration -->
                        <property name="Azure Storage Credentials Service">azure-storage-service</property>
                        <property name="Filesystem Name">nifi-data</property>
                        <property name="Directory Name">oracle-data/large/${now():format('yyyy/MM/dd')}</property>
                        <property name="File Name">${filename}</property>
                        
                        <!-- Performance Settings for Large Files -->
                        <property name="Block Size">64 MB</property>
                        <property name="Buffer Size">16 MB</property>
                        <property name="Number of Retries">3</property>
                        <property name="Create Directory">true</property>
                        
                        <!-- Conflict Resolution -->
                        <property name="Conflict Resolution Strategy">replace</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>2</maxConcurrentTasks>
                    <yieldDurationMillis>10000</yieldDurationMillis>
                </processor>
                
                <!-- 6. Update Processing Timestamp -->
                <processor>
                    <id>update-timestamp</id>
                    <name>Update-Processing-Timestamp</name>
                    <type>org.apache.nifi.processors.standard.UpdateAttribute</type>
                    <position x="1200" y="200"/>
                    
                    <properties>
                        <property name="processing.timestamp">${now():format('yyyy-MM-dd HH:mm:ss')}</property>
                        <property name="batch.id">${UUID()}</property>
                        <property name="source.system">oracle</property>
                        <property name="target.system">azure-data-lake</property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>4</maxConcurrentTasks>
                </processor>
                
                <!-- 7. Success Notification -->
                <processor>
                    <id>log-success</id>
                    <name>Log-Success-Notification</name>
                    <type>org.apache.nifi.processors.standard.LogMessage</type>
                    <position x="1400" y="200"/>
                    
                    <properties>
                        <property name="Log Level">INFO</property>
                        <property name="Log Prefix">ORACLE-TO-AZURE SUCCESS: </property>
                        <property name="Log Message">
                            Successfully transferred file: ${filename}, 
                            Size: ${fileSize}, 
                            Processing Time: ${processing.timestamp},
                            Batch ID: ${batch.id}
                        </property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>2</maxConcurrentTasks>
                </processor>
                
                <!-- Error Handling Processor -->
                <processor>
                    <id>handle-errors</id>
                    <name>Handle-Transfer-Errors</name>
                    <type>org.apache.nifi.processors.standard.LogMessage</type>
                    <position x="1000" y="400"/>
                    
                    <properties>
                        <property name="Log Level">ERROR</property>
                        <property name="Log Prefix">ORACLE-TO-AZURE ERROR: </property>
                        <property name="Log Message">
                            Failed to transfer file: ${filename}, 
                            Error: ${exception.message:replaceNull('Unknown error')},
                            Retry Count: ${retry.count:replaceNull('0')}
                        </property>
                    </properties>
                    
                    <!-- Scheduling -->
                    <schedulingStrategy>EVENT_DRIVEN</schedulingStrategy>
                    <maxConcurrentTasks>2</maxConcurrentTasks>
                </processor>
            </processors>
            
            <!-- Connections -->
            <connections>
                <!-- Oracle Query to Split -->
                <connection>
                    <id>oracle-to-split</id>
                    <name>Oracle-to-Split</name>
                    <source>
                        <id>query-oracle-processor</id>
                        <groupId>oracle-extraction-pg</groupId>
                    </source>
                    <destination>
                        <id>split-avro-processor</id>
                        <groupId>oracle-extraction-pg</groupId>
                    </destination>
                    <relationship>success</relationship>
                    <flowFileExpiration>24 hours</flowFileExpiration>
                    <backPressureDataSizeThreshold>10 GB</backPressureDataSizeThreshold>
                    <backPressureObjectThreshold>50000</backPressureObjectThreshold>
                </connection>
                
                <!-- Split to Compress -->
                <connection>
                    <id>split-to-compress</id>
                    <name>Split-to-Compress
